{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 4_CNN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# In this tutorial we will build basic CNN for image classification.\n",
        "Author :- Ankur Mali\n",
        "* We will define our model and learn how to use keras module to build custom layers\n",
        "* We will also design our own training loop, that is identical to model.fit in Keras.\n",
        "* The aim of this excercise is to teach, how to use exisiting Tensorflow API to construct our own module and integrate it with tf.keras API."
      ],
      "metadata": {
        "id": "iEL0LqOvNctE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SK3DMbzThNBc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(6218)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Things to do\n",
        "* Remember to Normalize your data and create validation split from train set.\n",
        "* Learn about tf.data, tf.slices and also tf.records"
      ],
      "metadata": {
        "id": "j3wnZ5tvOTCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_val = x_train[50000:60000]\n",
        "x_train = x_train[0:50000]\n",
        "y_val = y_train[50000:60000]\n",
        "y_train = y_train[0:50000]\n",
        "x_train = x_train.astype(np.float32).reshape(-1,28,28,1) / 255.0\n",
        "x_val = x_val.astype(np.float32).reshape(-1,28,28,1) / 255.0\n",
        "x_test = x_test.astype(np.float32).reshape(-1,28,28,1) / 255.0\n",
        "y_train = tf.one_hot(y_train, depth=10)\n",
        "y_val = tf.one_hot(y_val, depth=10)\n",
        "y_test = tf.one_hot(y_test, depth=10)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(x_val.shape)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(128)\n",
        "train_dataset_full = train_dataset.shuffle(buffer_size=1024).batch(len(train_dataset))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "val_dataset = val_dataset.batch(128)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_dataset = test_dataset.batch(128)\n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWo3ho3whTWU",
        "outputId": "c3dbd83a-aa95-480f-aed9-945f7e690516"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(50000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n",
            "391\n",
            "79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create your custom CNN class\n",
        "* Convolution layers has 4D weights of size (h,w,input_feature, output_feature), where h=height of your kernel and w = width of our kernel. If you add batches then it is 5D.\n",
        "* Now your model will convolve across your input feature map with kernel and create output feature map, that is then passed to next layer.\n",
        "* As we have learned in our prior class, to initialize your weights, we use tf.Variable(weight_init(size)), tf.keras.layers.Conv2D will do this for you. Play with the function and see how it works for your problem.\n",
        "* Few important concepts, learn to save your model after every k epochs and start re-training from last checkpoint. This is very useful, and you don't need to retrain your model from scratch.\n"
      ],
      "metadata": {
        "id": "Rs9r9QDvO48Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "class ImageRecognitionCNN_preactivation(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, num_classes, device='cpu:0', checkpoint_directory=None):\n",
        "        ''' Define the parameterized layers used during forward-pass, the device\n",
        "            where you would like to run the computation (GPU, TPU, CPU) on and the checkpoint\n",
        "            directory.\n",
        "            \n",
        "            Args:\n",
        "                num_classes: the number of labels in the network.\n",
        "                device: string, 'cpu:n' or 'gpu:n' (n can vary). Default, 'cpu:0'.\n",
        "                checkpoint_directory: the directory where you would like to save or \n",
        "                                      restore a model.\n",
        "        ''' \n",
        "        super(ImageRecognitionCNN_preactivation, self).__init__()\n",
        "        \n",
        "        # Initialize layers\n",
        "        self.conv1 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.conv2 = tf.keras.layers.Conv2D(64, 3,padding='same', activation=None)\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D()\n",
        "        self.conv3 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\n",
        "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
        "        self.conv4 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\n",
        "        self.bn4 = tf.keras.layers.BatchNormalization()\n",
        "        # self.pool2 = tf.keras.layers.MaxPool2D()\t\n",
        "        # self.conv5 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\t\n",
        "        # self.pool2 = tf.keras.layers.MaxPool2D()\t\n",
        "        # self.conv6 = tf.keras.layers.Conv2D(64, 3, 2, padding='same', activation=None)\t\n",
        "        # self.conv7 = tf.keras.layers.Conv2D(64, 1, padding='same', activation=None)\n",
        "        self.conv8 = tf.keras.layers.Conv2D(num_classes, 1, padding='same', activation=None)\n",
        "        \n",
        "        # Define the device \n",
        "        self.device = device\n",
        "        \n",
        "        # Define the checkpoint directory\n",
        "        self.checkpoint_directory = checkpoint_directory\n",
        "        self.acc = tf.keras.metrics.Accuracy()\n",
        "\n",
        "\n",
        "    def predict(self, images, training):\n",
        "        \"\"\" Predicts the probability of each class, based on the input sample.\n",
        "            \n",
        "            Args:\n",
        "                images: 4D tensor. Either an image or a batch of images.\n",
        "                training: Boolean. Either the network is predicting in\n",
        "                          training mode or not.\n",
        "        \"\"\"\n",
        "        x = self.conv1(images)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv8(x)\n",
        "        #x = tf.nn.relu(x)\t\n",
        "        #print(x.shape)\n",
        "        x = tf.reshape(x, (-1, 1, 10))\n",
        "        #x = tf.keras.layers.Flatten(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "    def loss_fn(self, images, target, training):\n",
        "        \"\"\" Defines the loss function used during \n",
        "            training.         \n",
        "        \"\"\"\n",
        "        preds = self.predict(images, training)\n",
        "        #print(preds.shape)\n",
        "        #print(target.shape)\n",
        "        loss = tf.nn.softmax_cross_entropy_with_logits(labels=target, logits=preds)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def grads_fn(self, images, target, training):\n",
        "        \"\"\" Dynamically computes the gradients of the loss value\n",
        "            with respect to the parameters of the model, in each\n",
        "            forward pass.\n",
        "        \"\"\"\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = self.loss_fn(images, target, training)\n",
        "        return tape.gradient(loss, self.variables)\n",
        "    \n",
        "    def restore_model(self):\n",
        "        \"\"\" Function to restore trained model.\n",
        "        \"\"\"\n",
        "        with tf.device(self.device):\n",
        "            # Run the model once to initialize variables\n",
        "            dummy_input = tf.constant(tf.zeros((1,48,48,1)))\n",
        "            dummy_pred = self.predict(dummy_input, training=False)\n",
        "            # Restore the variables of the model\n",
        "            saver = tf.Saver(self.variables)\n",
        "            saver.restore(tf.train.latest_checkpoint\n",
        "                          (self.checkpoint_directory))\n",
        "    \n",
        "    def save_model(self, global_step=0):\n",
        "        \"\"\" Function to save trained model.\n",
        "        \"\"\"\n",
        "        tf.Saver(self.variables).save(self.checkpoint_directory, \n",
        "                                       global_step=global_step)   \n",
        "    \n",
        "    # def compute_accuracy(self, input_data):\n",
        "    #     \"\"\" Compute the accuracy on the input data.\n",
        "    #     \"\"\"\n",
        "    #     with tf.device(self.device):\n",
        "    #         #acc = tf.metrics.Accuracy()\n",
        "    #         for step ,(images, targets) in enumerate(input_data):\n",
        "    #             # Predict the probability of each class\n",
        "    #             #print(targets.shape)\n",
        "    #             logits = self.predict(images, training=False)\n",
        "    #             # Select the class with the highest probability\n",
        "    #             #print(logits.shape)\n",
        "    #             logits = tf.nn.softmax(logits)\n",
        "    #             logits = tf.reshape(logits, [-1, 10])\n",
        "    #             targets = tf.reshape(targets, [-1,10])\n",
        "    #             preds = tf.argmax(logits, axis=1)\n",
        "                \n",
        "    #             #m1.update_state\n",
        "    #             # Compute the accuracy\n",
        "    #             #print(preds.shape)\n",
        "    #             acc(tf.reshape(targets, preds))\n",
        "    #     return acc\n",
        "\n",
        "    def compute_accuracy_2(self, images, targets):\n",
        "        \"\"\" Compute the accuracy on the input data.\n",
        "        \"\"\"\n",
        "        with tf.device(self.device):\n",
        "            \n",
        "            # Predict the probability of each class\n",
        "            logits = self.predict(images, training=False)\n",
        "            # Select the class with the highest probability\n",
        "            \n",
        "            logits = tf.nn.softmax(logits)\n",
        "            logits = tf.reshape(logits, [-1, 10])\n",
        "            targets = tf.reshape(targets, [-1,10])\n",
        "            preds = tf.argmax(logits, axis=1)\n",
        "            goal = tf.argmax(targets, axis=1)\n",
        "            self.acc.update_state(goal, preds)\n",
        "            # Compute the accuracy\n",
        "            result = self.acc.result().numpy()\n",
        "        return result\n",
        "\n",
        "  \n",
        "    def fit_fc(self, training_data, eval_data, optimizer, num_epochs=500, \n",
        "            early_stopping_rounds=10, verbose=10, train_from_scratch=False):\n",
        "        \"\"\" Function to train the model, using the selected optimizer and\n",
        "            for the desired number of epochs. You can either train from scratch\n",
        "            or load the latest model trained. Early stopping is used in order to\n",
        "            mitigate the risk of overfitting the network.\n",
        "            \n",
        "            Args:\n",
        "                training_data: the data you would like to train the model on.\n",
        "                                Must be in the tf.data.Dataset format.\n",
        "                eval_data: the data you would like to evaluate the model on.\n",
        "                            Must be in the tf.data.Dataset format.\n",
        "                optimizer: the optimizer used during training.\n",
        "                num_epochs: the maximum number of iterations you would like to \n",
        "                            train the model.\n",
        "                early_stopping_rounds: stop training if the loss on the eval \n",
        "                                       dataset does not decrease after n epochs.\n",
        "                verbose: int. Specify how often to print the loss value of the network.\n",
        "                train_from_scratch: boolean. Whether to initialize variables of the\n",
        "                                    the last trained model or initialize them\n",
        "                                    randomly.\n",
        "        \"\"\" \n",
        "    \n",
        "        if train_from_scratch==False:\n",
        "            self.restore_model()\n",
        "        \n",
        "        # Initialize best loss. This variable will store the lowest loss on the\n",
        "        # eval dataset.\n",
        "        best_loss = 999\n",
        "        \n",
        "        # Initialize classes to update the mean loss of train and eval\n",
        "        train_loss = tf.keras.metrics.Mean('train_loss')\n",
        "        eval_loss = tf.keras.metrics.Mean('eval_loss')\n",
        "        acc_train = tf.keras.metrics.Mean('train_acc')\n",
        "        acc_val = tf.keras.metrics.Mean('val_acc')\n",
        "        test_loss = tf.keras.metrics.Mean('test_loss')\n",
        "        acc_test = tf.keras.metrics.Mean('test_acc')\n",
        "        \n",
        "        # Initialize dictionary to store the loss history\n",
        "        self.history = {}\n",
        "        self.history['train_loss'] = []\n",
        "        self.history['eval_loss'] = []\n",
        "        self.history['train_acc'] = []\n",
        "        self.history['val_acc'] = []\n",
        "        self.history['test_loss'] = []\n",
        "        self.history['test_acc'] = []\n",
        "        \n",
        "        # Begin training\n",
        "        with tf.device(self.device):\n",
        "            for i in range(num_epochs):\n",
        "                # Training with gradient descent\n",
        "                #training_data_x = training_data.shuffle(buffer_size=1024).batch(128)\n",
        "                for step, (images, target) in enumerate(training_data):\n",
        "                    grads = self.grads_fn(images, target, True)\n",
        "                    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "                    \n",
        "                # Compute the loss on the training data after one epoch\n",
        "                for step, (images, target) in enumerate(training_data):\n",
        "                    loss = self.loss_fn(images, target, False)\n",
        "                    accuracy = self.compute_accuracy_2(images,target)\n",
        "                    acc_train(accuracy)\n",
        "                    train_loss(loss)\n",
        "\n",
        "                self.history['train_loss'].append(train_loss.result().numpy())\n",
        "                self.history['train_acc'].append(acc_train.result().numpy())\n",
        "\n",
        "\n",
        "                # Reset metrics\n",
        "                train_loss.reset_states()\n",
        "                acc_train.reset_states()\n",
        "\n",
        "                for step, (images, target) in enumerate(test_dataset):\n",
        "                    loss = self.loss_fn(images, target, False)\n",
        "                    accuracy = self.compute_accuracy_2(images,target)\n",
        "                    acc_test(accuracy)\n",
        "                    test_loss(loss)\n",
        "                self.history['test_loss'].append(test_loss.result().numpy())\n",
        "                self.history['test_acc'].append(acc_test.result().numpy())\n",
        "\n",
        "                # Reset metrics\n",
        "                test_loss.reset_states()\n",
        "                acc_test.reset_states()\n",
        "                \n",
        "                # Compute the loss on the eval data after one epoch\n",
        "                for step, (images, target) in enumerate(eval_data):\n",
        "                    loss = self.loss_fn(images, target, False)\n",
        "                    accuracy = self.compute_accuracy_2(images,target)\n",
        "                    acc_val(accuracy)\n",
        "                    eval_loss(loss)\n",
        "                self.history['eval_loss'].append(eval_loss.result().numpy())\n",
        "                self.history['val_acc'].append(acc_val.result().numpy())\n",
        "                # Reset metrics\n",
        "                eval_loss.reset_states()\n",
        "                acc_val.reset_states()\n",
        "                \n",
        "                # Print train and eval losses\n",
        "                if (i==0) | ((i+1)%verbose==0):\n",
        "                    print('Train loss at epoch %d: ' %(i+1), self.history['train_loss'][-1])\n",
        "                    print('Train Acc at epoch %d: ' %(i+1), self.history['train_acc'][-1])\n",
        "                    \n",
        "                    print('Eval loss at epoch %d: ' %(i+1), self.history['eval_loss'][-1])\n",
        "                    print('Eval Acc at epoch %d: ' %(i+1), self.history['val_acc'][-1])\n",
        "\n",
        "                    print('Test loss at epoch %d: ' %(i+1), self.history['test_loss'][-1])\n",
        "                    print('Test Acc at epoch %d: ' %(i+1), self.history['test_acc'][-1])\n",
        "\n",
        "                plt.plot(i + 1, self.history['train_acc'][-1], 'go-',label=\"Train accuracy\")\n",
        "                plt.plot(i + 1, self.history['val_acc'][-1], 'ro-',label=\"Validate accuracy\")\n",
        "                plt.plot(i + 1, self.history['test_acc'][-1], 'bo-',label=\"Test accuracy\")\n",
        "                '''\n",
        "                # Check for early stopping\n",
        "                if self.history['eval_loss'][-1]<best_loss:\n",
        "                    best_loss = self.history['eval_loss'][-1]\n",
        "                    count = early_stopping_rounds\n",
        "                else:\n",
        "                    count -= 1\n",
        "                if count==0:\n",
        "                    break\n",
        "                '''"
      ],
      "metadata": {
        "id": "KGjSk_lMhb7V",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path where you want to save/restore the trained variables.\n",
        "checkpoint_directory = 'models_checkpoints/mnist/'\n",
        "\n",
        "# Use the GPU if available.\n",
        "device = 'gpu:0'\n",
        "\n",
        "# Define optimizer.\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=1e-4)\n",
        "\n",
        "# Instantiate model. This doesn't initialize the variables yet.\n",
        "model = ImageRecognitionCNN_preactivation(num_classes=10, device=device, \n",
        "                              checkpoint_directory=checkpoint_directory)\n",
        "\n",
        "#model = ImageRecognitionCNN(num_classes=7, device=device)\n",
        "# Train model\n",
        "model.fit_fc(train_dataset, val_dataset, optimizer, num_epochs=40, \n",
        "          early_stopping_rounds=2, verbose=2, train_from_scratch=True)"
      ],
      "metadata": {
        "id": "4a-iuiHIypry",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "59d9e9ea-99e0-455e-bd78-472857f6b0de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at epoch 1:  1.8244275\n",
            "Train Acc at epoch 1:  0.25695008\n",
            "Eval loss at epoch 1:  1.8055395\n",
            "Eval Acc at epoch 1:  0.25746763\n",
            "Test loss at epoch 1:  1.8008385\n",
            "Test Acc at epoch 1:  0.25629795\n",
            "Train loss at epoch 2:  0.09037596\n",
            "Train Acc at epoch 2:  0.43474245\n",
            "Eval loss at epoch 2:  0.08852736\n",
            "Eval Acc at epoch 2:  0.6051279\n",
            "Test loss at epoch 2:  0.08961722\n",
            "Test Acc at epoch 2:  0.5750143\n",
            "Train loss at epoch 4:  0.044805035\n",
            "Train Acc at epoch 4:  0.76626176\n",
            "Eval loss at epoch 4:  0.05507896\n",
            "Eval Acc at epoch 4:  0.79934704\n",
            "Test loss at epoch 4:  0.053419806\n",
            "Test Acc at epoch 4:  0.7922537\n",
            "Train loss at epoch 6:  0.028105527\n",
            "Train Acc at epoch 6:  0.85010576\n",
            "Eval loss at epoch 6:  0.043296203\n",
            "Eval Acc at epoch 6:  0.8640166\n",
            "Test loss at epoch 6:  0.04030323\n",
            "Test Acc at epoch 6:  0.8609222\n",
            "Train loss at epoch 8:  0.021695245\n",
            "Train Acc at epoch 8:  0.88910466\n",
            "Eval loss at epoch 8:  0.04217901\n",
            "Eval Acc at epoch 8:  0.8967039\n",
            "Test loss at epoch 8:  0.038497657\n",
            "Test Acc at epoch 8:  0.89499015\n",
            "Train loss at epoch 10:  0.012403235\n",
            "Train Acc at epoch 10:  0.9117621\n",
            "Eval loss at epoch 10:  0.036524266\n",
            "Eval Acc at epoch 10:  0.9166215\n",
            "Test loss at epoch 10:  0.031830102\n",
            "Test Acc at epoch 10:  0.91552967\n",
            "Train loss at epoch 12:  0.00893085\n",
            "Train Acc at epoch 12:  0.92661965\n",
            "Eval loss at epoch 12:  0.034104846\n",
            "Eval Acc at epoch 12:  0.929958\n",
            "Test loss at epoch 12:  0.030732067\n",
            "Test Acc at epoch 12:  0.92921853\n",
            "Train loss at epoch 14:  0.0052559343\n",
            "Train Acc at epoch 14:  0.93712085\n",
            "Eval loss at epoch 14:  0.033385545\n",
            "Eval Acc at epoch 14:  0.9395643\n",
            "Test loss at epoch 14:  0.02870595\n",
            "Test Acc at epoch 14:  0.9390245\n",
            "Train loss at epoch 16:  0.0054713427\n",
            "Train Acc at epoch 16:  0.9449485\n",
            "Eval loss at epoch 16:  0.034365434\n",
            "Eval Acc at epoch 16:  0.9467875\n",
            "Test loss at epoch 16:  0.029741747\n",
            "Test Acc at epoch 16:  0.9463887\n",
            "Train loss at epoch 18:  0.0021697707\n",
            "Train Acc at epoch 18:  0.95098\n",
            "Eval loss at epoch 18:  0.029387299\n",
            "Eval Acc at epoch 18:  0.95244867\n",
            "Test loss at epoch 18:  0.025558684\n",
            "Test Acc at epoch 18:  0.9521279\n",
            "Train loss at epoch 20:  0.001669641\n",
            "Train Acc at epoch 20:  0.95579106\n",
            "Eval loss at epoch 20:  0.029986825\n",
            "Eval Acc at epoch 20:  0.9569704\n",
            "Test loss at epoch 20:  0.026323343\n",
            "Test Acc at epoch 20:  0.9567135\n",
            "Train loss at epoch 22:  0.000917845\n",
            "Train Acc at epoch 22:  0.95970464\n",
            "Eval loss at epoch 22:  0.029095246\n",
            "Eval Acc at epoch 22:  0.96067905\n",
            "Test loss at epoch 22:  0.0251291\n",
            "Test Acc at epoch 22:  0.9604664\n",
            "Train loss at epoch 24:  0.0007102479\n",
            "Train Acc at epoch 24:  0.96295816\n",
            "Eval loss at epoch 24:  0.0298793\n",
            "Eval Acc at epoch 24:  0.96377546\n",
            "Test loss at epoch 24:  0.025051849\n",
            "Test Acc at epoch 24:  0.9635992\n",
            "Train loss at epoch 26:  0.0004073124\n",
            "Train Acc at epoch 26:  0.9656973\n",
            "Eval loss at epoch 26:  0.02863511\n",
            "Eval Acc at epoch 26:  0.9663897\n",
            "Test loss at epoch 26:  0.025320891\n",
            "Test Acc at epoch 26:  0.9662418\n",
            "Train loss at epoch 28:  0.00032943112\n",
            "Train Acc at epoch 28:  0.9680445\n",
            "Eval loss at epoch 28:  0.031115351\n",
            "Eval Acc at epoch 28:  0.96864176\n",
            "Test loss at epoch 28:  0.024100857\n",
            "Test Acc at epoch 28:  0.96851516\n",
            "Train loss at epoch 30:  0.013363271\n",
            "Train Acc at epoch 30:  0.9700242\n",
            "Eval loss at epoch 30:  0.051475927\n",
            "Eval Acc at epoch 30:  0.9704548\n",
            "Test loss at epoch 30:  0.04630186\n",
            "Test Acc at epoch 30:  0.97037023\n",
            "Train loss at epoch 32:  0.00045663436\n",
            "Train Acc at epoch 32:  0.97161883\n",
            "Eval loss at epoch 32:  0.02948838\n",
            "Eval Acc at epoch 32:  0.9720789\n",
            "Test loss at epoch 32:  0.02358602\n",
            "Test Acc at epoch 32:  0.9719827\n",
            "Train loss at epoch 34:  0.0001912533\n",
            "Train Acc at epoch 34:  0.9731983\n",
            "Eval loss at epoch 34:  0.028587235\n",
            "Eval Acc at epoch 34:  0.9736051\n",
            "Test loss at epoch 34:  0.023082312\n",
            "Test Acc at epoch 34:  0.97352165\n",
            "Train loss at epoch 36:  0.000170613\n",
            "Train Acc at epoch 36:  0.974599\n",
            "Eval loss at epoch 36:  0.02845691\n",
            "Eval Acc at epoch 36:  0.97496045\n",
            "Test loss at epoch 36:  0.022953039\n",
            "Test Acc at epoch 36:  0.97488695\n",
            "Train loss at epoch 38:  0.00012142437\n",
            "Train Acc at epoch 38:  0.9758518\n",
            "Eval loss at epoch 38:  0.028710926\n",
            "Eval Acc at epoch 38:  0.9761768\n",
            "Test loss at epoch 38:  0.023172595\n",
            "Test Acc at epoch 38:  0.976111\n",
            "Train loss at epoch 40:  8.845395e-05\n",
            "Train Acc at epoch 40:  0.97697836\n",
            "Eval loss at epoch 40:  0.029194312\n",
            "Eval Acc at epoch 40:  0.9772709\n",
            "Test loss at epoch 40:  0.023141788\n",
            "Test Acc at epoch 40:  0.97721267\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "class ImageRecognitionCNN_postactivation(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, num_classes, device='cpu:0', checkpoint_directory=None):\n",
        "        ''' Define the parameterized layers used during forward-pass, the device\n",
        "            where you would like to run the computation (GPU, TPU, CPU) on and the checkpoint\n",
        "            directory.\n",
        "            \n",
        "            Args:\n",
        "                num_classes: the number of labels in the network.\n",
        "                device: string, 'cpu:n' or 'gpu:n' (n can vary). Default, 'cpu:0'.\n",
        "                checkpoint_directory: the directory where you would like to save or \n",
        "                                      restore a model.\n",
        "        ''' \n",
        "        super(ImageRecognitionCNN_postactivation, self).__init__()\n",
        "        \n",
        "        # Initialize layers\n",
        "        self.conv1 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.conv2 = tf.keras.layers.Conv2D(64, 3,padding='same', activation=None)\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D()\n",
        "        self.conv3 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\n",
        "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
        "        self.conv4 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\n",
        "        self.bn4 = tf.keras.layers.BatchNormalization()\n",
        "        # self.pool2 = tf.keras.layers.MaxPool2D()\t\n",
        "        # self.conv5 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\t\n",
        "        # self.pool2 = tf.keras.layers.MaxPool2D()\t\n",
        "        # self.conv6 = tf.keras.layers.Conv2D(64, 3, 2, padding='same', activation=None)\t\n",
        "        # self.conv7 = tf.keras.layers.Conv2D(64, 1, padding='same', activation=None)\n",
        "        self.conv8 = tf.keras.layers.Conv2D(num_classes, 1, padding='same', activation=None)\n",
        "        \n",
        "        # Define the device \n",
        "        self.device = device\n",
        "        \n",
        "        # Define the checkpoint directory\n",
        "        self.checkpoint_directory = checkpoint_directory\n",
        "        self.acc = tf.keras.metrics.Accuracy()\n",
        "\n",
        "\n",
        "    def predict(self, images, training):\n",
        "        \"\"\" Predicts the probability of each class, based on the input sample.\n",
        "            \n",
        "            Args:\n",
        "                images: 4D tensor. Either an image or a batch of images.\n",
        "                training: Boolean. Either the network is predicting in\n",
        "                          training mode or not.\n",
        "        \"\"\"\n",
        "        x = self.conv1(images)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.bn2(x, training=training)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv3(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.bn3(x, training=training)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv4(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.bn4(x, training=training)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv8(x)\n",
        "        #x = tf.nn.relu(x)\t\n",
        "        #print(x.shape)\n",
        "        x = tf.reshape(x, (-1, 1, 10))\n",
        "        #x = tf.keras.layers.Flatten(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "    def loss_fn(self, images, target, training):\n",
        "        \"\"\" Defines the loss function used during \n",
        "            training.         \n",
        "        \"\"\"\n",
        "        preds = self.predict(images, training)\n",
        "        #print(preds.shape)\n",
        "        #print(target.shape)\n",
        "        loss = tf.nn.softmax_cross_entropy_with_logits(labels=target, logits=preds)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def grads_fn(self, images, target, training):\n",
        "        \"\"\" Dynamically computes the gradients of the loss value\n",
        "            with respect to the parameters of the model, in each\n",
        "            forward pass.\n",
        "        \"\"\"\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = self.loss_fn(images, target, training)\n",
        "        return tape.gradient(loss, self.variables)\n",
        "    \n",
        "    def restore_model(self):\n",
        "        \"\"\" Function to restore trained model.\n",
        "        \"\"\"\n",
        "        with tf.device(self.device):\n",
        "            # Run the model once to initialize variables\n",
        "            dummy_input = tf.constant(tf.zeros((1,48,48,1)))\n",
        "            dummy_pred = self.predict(dummy_input, training=False)\n",
        "            # Restore the variables of the model\n",
        "            saver = tf.Saver(self.variables)\n",
        "            saver.restore(tf.train.latest_checkpoint\n",
        "                          (self.checkpoint_directory))\n",
        "    \n",
        "    def save_model(self, global_step=0):\n",
        "        \"\"\" Function to save trained model.\n",
        "        \"\"\"\n",
        "        tf.Saver(self.variables).save(self.checkpoint_directory, \n",
        "                                       global_step=global_step)   \n",
        "    \n",
        "    # def compute_accuracy(self, input_data):\n",
        "    #     \"\"\" Compute the accuracy on the input data.\n",
        "    #     \"\"\"\n",
        "    #     with tf.device(self.device):\n",
        "    #         #acc = tf.metrics.Accuracy()\n",
        "    #         for step ,(images, targets) in enumerate(input_data):\n",
        "    #             # Predict the probability of each class\n",
        "    #             #print(targets.shape)\n",
        "    #             logits = self.predict(images, training=False)\n",
        "    #             # Select the class with the highest probability\n",
        "    #             #print(logits.shape)\n",
        "    #             logits = tf.nn.softmax(logits)\n",
        "    #             logits = tf.reshape(logits, [-1, 10])\n",
        "    #             targets = tf.reshape(targets, [-1,10])\n",
        "    #             preds = tf.argmax(logits, axis=1)\n",
        "                \n",
        "    #             #m1.update_state\n",
        "    #             # Compute the accuracy\n",
        "    #             #print(preds.shape)\n",
        "    #             acc(tf.reshape(targets, preds))\n",
        "    #     return acc\n",
        "\n",
        "    def compute_accuracy_2(self, images, targets):\n",
        "        \"\"\" Compute the accuracy on the input data.\n",
        "        \"\"\"\n",
        "        with tf.device(self.device):\n",
        "            \n",
        "            # Predict the probability of each class\n",
        "            logits = self.predict(images, training=False)\n",
        "            # Select the class with the highest probability\n",
        "            \n",
        "            logits = tf.nn.softmax(logits)\n",
        "            logits = tf.reshape(logits, [-1, 10])\n",
        "            targets = tf.reshape(targets, [-1,10])\n",
        "            preds = tf.argmax(logits, axis=1)\n",
        "            goal = tf.argmax(targets, axis=1)\n",
        "            self.acc.update_state(goal, preds)\n",
        "            # Compute the accuracy\n",
        "            result = self.acc.result().numpy()\n",
        "        return result\n",
        "\n",
        "  \n",
        "    def fit_fc(self, training_data, eval_data, optimizer, num_epochs=500, \n",
        "            early_stopping_rounds=10, verbose=10, train_from_scratch=False):\n",
        "        \"\"\" Function to train the model, using the selected optimizer and\n",
        "            for the desired number of epochs. You can either train from scratch\n",
        "            or load the latest model trained. Early stopping is used in order to\n",
        "            mitigate the risk of overfitting the network.\n",
        "            \n",
        "            Args:\n",
        "                training_data: the data you would like to train the model on.\n",
        "                                Must be in the tf.data.Dataset format.\n",
        "                eval_data: the data you would like to evaluate the model on.\n",
        "                            Must be in the tf.data.Dataset format.\n",
        "                optimizer: the optimizer used during training.\n",
        "                num_epochs: the maximum number of iterations you would like to \n",
        "                            train the model.\n",
        "                early_stopping_rounds: stop training if the loss on the eval \n",
        "                                       dataset does not decrease after n epochs.\n",
        "                verbose: int. Specify how often to print the loss value of the network.\n",
        "                train_from_scratch: boolean. Whether to initialize variables of the\n",
        "                                    the last trained model or initialize them\n",
        "                                    randomly.\n",
        "        \"\"\" \n",
        "    \n",
        "        if train_from_scratch==False:\n",
        "            self.restore_model()\n",
        "        \n",
        "        # Initialize best loss. This variable will store the lowest loss on the\n",
        "        # eval dataset.\n",
        "        best_loss = 999\n",
        "        \n",
        "        # Initialize classes to update the mean loss of train and eval\n",
        "        train_loss = tf.keras.metrics.Mean('train_loss')\n",
        "        eval_loss = tf.keras.metrics.Mean('eval_loss')\n",
        "        acc_train = tf.keras.metrics.Mean('train_acc')\n",
        "        acc_val = tf.keras.metrics.Mean('val_acc')\n",
        "        test_loss = tf.keras.metrics.Mean('test_loss')\n",
        "        acc_test = tf.keras.metrics.Mean('test_acc')\n",
        "        \n",
        "        # Initialize dictionary to store the loss history\n",
        "        self.history = {}\n",
        "        self.history['train_loss'] = []\n",
        "        self.history['eval_loss'] = []\n",
        "        self.history['train_acc'] = []\n",
        "        self.history['val_acc'] = []\n",
        "        self.history['test_loss'] = []\n",
        "        self.history['test_acc'] = []\n",
        "        \n",
        "        # Begin training\n",
        "        with tf.device(self.device):\n",
        "            for i in range(num_epochs):\n",
        "                # Training with gradient descent\n",
        "                #training_data_x = training_data.shuffle(buffer_size=1024).batch(128)\n",
        "                for step, (images, target) in enumerate(training_data):\n",
        "                    grads = self.grads_fn(images, target, True)\n",
        "                    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "                    \n",
        "                # Compute the loss on the training data after one epoch\n",
        "                for step, (images, target) in enumerate(training_data):\n",
        "                    loss = self.loss_fn(images, target, False)\n",
        "                    accuracy = self.compute_accuracy_2(images,target)\n",
        "                    acc_train(accuracy)\n",
        "                    train_loss(loss)\n",
        "\n",
        "                self.history['train_loss'].append(train_loss.result().numpy())\n",
        "                self.history['train_acc'].append(acc_train.result().numpy())\n",
        "\n",
        "\n",
        "                # Reset metrics\n",
        "                train_loss.reset_states()\n",
        "                acc_train.reset_states()\n",
        "\n",
        "                for step, (images, target) in enumerate(test_dataset):\n",
        "                    loss = self.loss_fn(images, target, False)\n",
        "                    accuracy = self.compute_accuracy_2(images,target)\n",
        "                    acc_test(accuracy)\n",
        "                    test_loss(loss)\n",
        "                self.history['test_loss'].append(test_loss.result().numpy())\n",
        "                self.history['test_acc'].append(acc_test.result().numpy())\n",
        "\n",
        "                # Reset metrics\n",
        "                test_loss.reset_states()\n",
        "                acc_test.reset_states()\n",
        "                \n",
        "                # Compute the loss on the eval data after one epoch\n",
        "                for step, (images, target) in enumerate(eval_data):\n",
        "                    loss = self.loss_fn(images, target, False)\n",
        "                    accuracy = self.compute_accuracy_2(images,target)\n",
        "                    acc_val(accuracy)\n",
        "                    eval_loss(loss)\n",
        "                self.history['eval_loss'].append(eval_loss.result().numpy())\n",
        "                self.history['val_acc'].append(acc_val.result().numpy())\n",
        "                # Reset metrics\n",
        "                eval_loss.reset_states()\n",
        "                acc_val.reset_states()\n",
        "                \n",
        "                # Print train and eval losses\n",
        "                if (i==0) | ((i+1)%verbose==0):\n",
        "                    print('Train loss at epoch %d: ' %(i+1), self.history['train_loss'][-1])\n",
        "                    print('Train Acc at epoch %d: ' %(i+1), self.history['train_acc'][-1])\n",
        "                    \n",
        "                    print('Eval loss at epoch %d: ' %(i+1), self.history['eval_loss'][-1])\n",
        "                    print('Eval Acc at epoch %d: ' %(i+1), self.history['val_acc'][-1])\n",
        "\n",
        "                    print('Test loss at epoch %d: ' %(i+1), self.history['test_loss'][-1])\n",
        "                    print('Test Acc at epoch %d: ' %(i+1), self.history['test_acc'][-1])\n",
        "\n",
        "                plt.plot(i + 1, self.history['train_acc'][-1], 'go-',label=\"Train accuracy\")\n",
        "                plt.plot(i + 1, self.history['val_acc'][-1], 'ro-',label=\"Validate accuracy\")\n",
        "                plt.plot(i + 1, self.history['test_acc'][-1], 'bo-',label=\"Test accuracy\")\n",
        "                '''\n",
        "                # Check for early stopping\n",
        "                if self.history['eval_loss'][-1]<best_loss:\n",
        "                    best_loss = self.history['eval_loss'][-1]\n",
        "                    count = early_stopping_rounds\n",
        "                else:\n",
        "                    count -= 1\n",
        "                if count==0:\n",
        "                    break\n",
        "                '''"
      ],
      "metadata": {
        "id": "igbClsJ3tQ1y",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path where you want to save/restore the trained variables.\n",
        "checkpoint_directory = 'models_checkpoints/mnist/'\n",
        "\n",
        "# Use the GPU if available.\n",
        "device = 'gpu:0'\n",
        "\n",
        "# Define optimizer.\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=1e-4)\n",
        "\n",
        "# Instantiate model. This doesn't initialize the variables yet.\n",
        "model = ImageRecognitionCNN_postactivation(num_classes=10, device=device, \n",
        "                              checkpoint_directory=checkpoint_directory)\n",
        "\n",
        "#model = ImageRecognitionCNN(num_classes=7, device=device)\n",
        "# Train model\n",
        "model.fit_fc(train_dataset, val_dataset, optimizer, num_epochs=40, \n",
        "          early_stopping_rounds=2, verbose=2, train_from_scratch=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "exUkL_OBytBw",
        "outputId": "20e978ea-d17d-4f2f-8c6c-01531863f221"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at epoch 1:  0.8147978\n",
            "Train Acc at epoch 1:  0.84060794\n",
            "Eval loss at epoch 1:  0.7838626\n",
            "Eval Acc at epoch 1:  0.83866537\n",
            "Test loss at epoch 1:  0.7988489\n",
            "Test Acc at epoch 1:  0.83648634\n",
            "Train loss at epoch 2:  0.076950915\n",
            "Train Acc at epoch 2:  0.8742485\n",
            "Eval loss at epoch 2:  0.08103323\n",
            "Eval Acc at epoch 2:  0.90691453\n",
            "Test loss at epoch 2:  0.08590199\n",
            "Test Acc at epoch 2:  0.9012313\n",
            "Train loss at epoch 4:  0.032978307\n",
            "Train Acc at epoch 4:  0.94056565\n",
            "Eval loss at epoch 4:  0.0519481\n",
            "Eval Acc at epoch 4:  0.9478187\n",
            "Test loss at epoch 4:  0.05805778\n",
            "Test Acc at epoch 4:  0.946412\n",
            "Train loss at epoch 6:  0.017513035\n",
            "Train Acc at epoch 6:  0.95972794\n",
            "Eval loss at epoch 6:  0.044880085\n",
            "Eval Acc at epoch 6:  0.9629502\n",
            "Test loss at epoch 6:  0.049408957\n",
            "Test Acc at epoch 6:  0.9623648\n",
            "Train loss at epoch 8:  0.00942751\n",
            "Train Acc at epoch 8:  0.9691836\n",
            "Eval loss at epoch 8:  0.044200707\n",
            "Eval Acc at epoch 8:  0.9709988\n",
            "Test loss at epoch 8:  0.047505453\n",
            "Test Acc at epoch 8:  0.97070485\n",
            "Train loss at epoch 10:  0.005831549\n",
            "Train Acc at epoch 10:  0.9748276\n",
            "Eval loss at epoch 10:  0.043116573\n",
            "Eval Acc at epoch 10:  0.975978\n",
            "Test loss at epoch 10:  0.046824034\n",
            "Test Acc at epoch 10:  0.9758075\n",
            "Train loss at epoch 12:  0.0035142316\n",
            "Train Acc at epoch 12:  0.97853976\n",
            "Eval loss at epoch 12:  0.04330525\n",
            "Eval Acc at epoch 12:  0.97932947\n",
            "Test loss at epoch 12:  0.047164906\n",
            "Test Acc at epoch 12:  0.9792266\n",
            "Train loss at epoch 14:  0.0021296665\n",
            "Train Acc at epoch 14:  0.98116815\n",
            "Eval loss at epoch 14:  0.04056431\n",
            "Eval Acc at epoch 14:  0.9817397\n",
            "Test loss at epoch 14:  0.044961177\n",
            "Test Acc at epoch 14:  0.98167235\n",
            "Train loss at epoch 16:  0.0016015575\n",
            "Train Acc at epoch 16:  0.9831506\n",
            "Eval loss at epoch 16:  0.041783776\n",
            "Eval Acc at epoch 16:  0.9835856\n",
            "Test loss at epoch 16:  0.046992395\n",
            "Test Acc at epoch 16:  0.9835412\n",
            "Train loss at epoch 18:  0.0057327873\n",
            "Train Acc at epoch 18:  0.9845253\n",
            "Eval loss at epoch 18:  0.040252354\n",
            "Eval Acc at epoch 18:  0.98484975\n",
            "Test loss at epoch 18:  0.046305217\n",
            "Test Acc at epoch 18:  0.98481625\n",
            "Train loss at epoch 20:  0.0006994961\n",
            "Train Acc at epoch 20:  0.9857323\n",
            "Eval loss at epoch 20:  0.03546279\n",
            "Eval Acc at epoch 20:  0.9860271\n",
            "Test loss at epoch 20:  0.038691748\n",
            "Test Acc at epoch 20:  0.9859958\n",
            "Train loss at epoch 22:  0.00034462844\n",
            "Train Acc at epoch 22:  0.98679596\n",
            "Eval loss at epoch 22:  0.03529286\n",
            "Eval Acc at epoch 22:  0.98704433\n",
            "Test loss at epoch 22:  0.039814085\n",
            "Test Acc at epoch 22:  0.9870176\n",
            "Train loss at epoch 24:  0.0002456964\n",
            "Train Acc at epoch 24:  0.98768723\n",
            "Eval loss at epoch 24:  0.034922358\n",
            "Eval Acc at epoch 24:  0.9878917\n",
            "Test loss at epoch 24:  0.040912237\n",
            "Test Acc at epoch 24:  0.98787177\n",
            "Train loss at epoch 26:  0.00017764272\n",
            "Train Acc at epoch 26:  0.9884346\n",
            "Eval loss at epoch 26:  0.034713227\n",
            "Eval Acc at epoch 26:  0.98860884\n",
            "Test loss at epoch 26:  0.04109644\n",
            "Test Acc at epoch 26:  0.9885944\n",
            "Train loss at epoch 28:  0.013746008\n",
            "Train Acc at epoch 28:  0.9890088\n",
            "Eval loss at epoch 28:  0.046092954\n",
            "Eval Acc at epoch 28:  0.98907024\n",
            "Test loss at epoch 28:  0.0505756\n",
            "Test Acc at epoch 28:  0.98907703\n",
            "Train loss at epoch 30:  0.00068842224\n",
            "Train Acc at epoch 30:  0.989462\n",
            "Eval loss at epoch 30:  0.036900096\n",
            "Eval Acc at epoch 30:  0.98958945\n",
            "Test loss at epoch 30:  0.039798867\n",
            "Test Acc at epoch 30:  0.98958194\n",
            "Train loss at epoch 32:  0.00021901594\n",
            "Train Acc at epoch 32:  0.9899613\n",
            "Eval loss at epoch 32:  0.034024578\n",
            "Eval Acc at epoch 32:  0.9900791\n",
            "Test loss at epoch 32:  0.037049703\n",
            "Test Acc at epoch 32:  0.99007076\n",
            "Train loss at epoch 34:  0.0001461998\n",
            "Train Acc at epoch 34:  0.99040985\n",
            "Eval loss at epoch 34:  0.034175973\n",
            "Eval Acc at epoch 34:  0.9905125\n",
            "Test loss at epoch 34:  0.036978144\n",
            "Test Acc at epoch 34:  0.99050766\n",
            "Train loss at epoch 36:  9.921275e-05\n",
            "Train Acc at epoch 36:  0.99080807\n",
            "Eval loss at epoch 36:  0.03488025\n",
            "Eval Acc at epoch 36:  0.9909\n",
            "Test loss at epoch 36:  0.037073106\n",
            "Test Acc at epoch 36:  0.9908957\n",
            "Train loss at epoch 38:  7.5838085e-05\n",
            "Train Acc at epoch 38:  0.9911671\n",
            "Eval loss at epoch 38:  0.03467083\n",
            "Eval Acc at epoch 38:  0.9912487\n",
            "Test loss at epoch 38:  0.03741109\n",
            "Test Acc at epoch 38:  0.991246\n",
            "Train loss at epoch 40:  5.9750066e-05\n",
            "Train Acc at epoch 40:  0.9914859\n",
            "Eval loss at epoch 40:  0.03490773\n",
            "Eval Acc at epoch 40:  0.99155927\n",
            "Test loss at epoch 40:  0.038334224\n",
            "Test Acc at epoch 40:  0.99155796\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}